{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all imports related to data engineering\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the training json file, then close the file\n",
    "file = open(\"raw_data/train.json\")\n",
    "raw_data = json.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pii_number_encoding = {\n",
    "    'B-NAME_STUDENT': 1, \n",
    "    'I-NAME_STUDENT': 2, \n",
    "    'B-URL_PERSONAL': 3, \n",
    "    'B-EMAIL': 4, \n",
    "    'B-ID_NUM': 5, \n",
    "    'I-URL_PERSONAL': 6, \n",
    "    'B-USERNAME': 7, \n",
    "    'I-PHONE_NUM': 8,  \n",
    "    'B-STREET_ADDRESS': 9, \n",
    "    'I-STREET_ADDRESS': 10,  \n",
    "    'B-PHONE_NUM': 11, \n",
    "    'I-ID_NUM': 12,\n",
    "    'O': 13\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'of', 'to', 'and', 'a', 'in', 'is', 'it', 'you', 'that', 'he', 'was', 'for', 'on', 'are', 'with', 'as', 'I', 'his', 'they', 'be', 'at', 'one', 'have', 'this', 'from', 'or', 'had', 'by', 'not', 'word', 'but', 'what', 'some', 'we', 'can', 'out', 'other', 'were', 'all', 'there', 'when', 'up', 'use', 'your', 'how', 'said', 'an', 'each', 'she', 'which', 'do', 'their', 'time', 'if', 'will', 'way', 'about', 'many', 'then', 'them', 'write', 'would', 'like', 'so', 'these', 'her', 'long', 'make', 'thing', 'see', 'him', 'two', 'has', 'look', 'more', 'day', 'could', 'go', 'come', 'did', 'number', 'sound', 'no', 'most', 'people', 'my', 'over', 'know', 'water', 'than', 'call', 'first', 'who', 'may', 'down', 'side', 'been', 'now', 'find', 'any', 'new', 'work', 'part', 'take', 'get', 'place', 'made', 'live', 'where', 'after', 'back', 'little', 'only', 'round', 'man', 'year', 'came', 'show', 'every', 'good', 'me', 'give', 'our', 'under', 'name', 'very', 'through', 'just', 'form', 'sentence', 'great', 'think', 'say', 'help', 'low', 'line', 'differ', 'turn', 'cause', 'much', 'mean', 'before', 'move', 'right', 'boy', 'old', 'too', 'same', 'tell', 'does', 'set', 'three', 'want', 'air', 'well', 'also', 'play', 'small', 'end', 'put', 'home', 'read', 'hand', 'port', 'large', 'spell', 'add', 'even', 'land', 'here', 'must', 'big', 'high', 'such', 'follow', 'act', 'why', 'ask', 'men', 'change', 'went', 'light', 'kind', 'off', 'need', 'house', 'picture', 'try', 'us', 'again', 'animal', 'point', 'mother', 'world', 'near', 'build', 'self', 'earth', 'father', 'head', 'stand', 'own', 'page', 'should', 'country', 'found', 'answer', 'school', 'grow', 'study', 'still', 'learn', 'plant', 'cover', 'food', 'sun', 'four', 'between', 'state', 'keep', 'eye', 'never', 'last', 'let', 'thought', 'city', 'tree', 'cross', 'farm', 'hard', 'start', 'might', 'story', 'saw', 'far', 'sea', 'draw', 'left', 'late', 'run', \"don't\", 'while', 'press', 'close', 'night', 'real', 'life', 'few', 'north', 'open', 'seem', 'together', 'next', 'white', 'children', 'begin', 'got', 'walk', 'example', 'ease', 'paper', 'group', 'always', 'music', 'those', 'both', 'mark', 'often', 'letter', 'until', 'mile', 'river', 'car', 'feet', 'care', 'second', 'book', 'carry', 'took', 'science', 'eat', 'room', 'friend', 'began', 'idea', 'fish', 'mountain', 'stop', 'once', 'base', 'hear', 'horse', 'cut', 'sure', 'watch', 'color', 'face', 'wood', 'main', 'enough', 'plain', 'girl', 'usual', 'young', 'ready', 'above', 'ever', 'red', 'list', 'though', 'feel', 'talk', 'bird', 'soon', 'body', 'dog', 'family', 'direct', 'pose', 'leave', 'song', 'measure', 'door', 'product', 'black', 'short', 'numeral', 'class', 'wind', 'question', 'happen', 'complete', 'ship', 'area', 'half', 'rock', 'order', 'fire', 'south', 'problem', 'piece', 'told', 'knew', 'pass', 'since', 'top', 'whole', 'king', 'space', 'heard', 'best', 'hour', 'better', 'true', 'during', 'hundred', 'five', 'remember', 'step', 'early', 'hold', 'west', 'ground', 'interest', 'reach', 'fast', 'verb', 'sing', 'listen', 'six', 'table', 'travel', 'less', 'morning', 'ten', 'simple', 'several', 'vowel', 'toward', 'war', 'lay', 'against', 'pattern', 'slow', 'center', 'love', 'person', 'money', 'serve', 'appear', 'road', 'map', 'rain', 'rule', 'govern', 'pull', 'cold', 'notice', 'voice', 'unit', 'power', 'town', 'fine', 'certain', 'fly', 'fall', 'lead', 'cry', 'dark', 'machine', 'note', 'wait', 'plan', 'figure', 'star', 'box', 'noun', 'field', 'rest', 'correct', 'able', 'pound', 'done', 'beauty', 'drive', 'stood', 'contain', 'front', 'teach', 'week', 'final', 'gave', 'green', 'oh', 'quick', 'develop', 'ocean', 'warm', 'free', 'minute', 'strong', 'special', 'mind', 'behind', 'clear', 'tail', 'produce', 'fact', 'street', 'inch', 'multiply', 'nothing', 'course', 'stay', 'wheel', 'full', 'force', 'blue', 'object', 'decide', 'surface', 'deep', 'moon', 'island', 'foot', 'system', 'busy', 'test', 'record', 'boat', 'common', 'gold', 'possible', 'plane', 'stead', 'dry', 'wonder', 'laugh', 'thousand', 'ago', 'ran', 'check', 'game', 'shape', 'equate', 'hot', 'miss', 'brought', 'heat', 'snow', 'tire', 'bring', 'yes', 'distant', 'fill', 'east', 'paint', 'language', 'among', 'grand', 'ball', 'yet', 'wave', 'drop', 'heart', 'am', 'present', 'heavy', 'dance', 'engine', 'position', 'arm', 'wide', 'sail', 'material', 'size', 'vary', 'settle', 'speak', 'weight', 'general', 'ice', 'matter', 'circle', 'pair', 'include', 'divide', 'syllable', 'felt', 'perhaps', 'pick', 'sudden', 'count', 'square', 'reason', 'length', 'represent', 'art', 'subject', 'region', 'energy', 'hunt', 'probable', 'bed', 'brother', 'egg', 'ride', 'cell', 'believe', 'fraction', 'forest', 'sit', 'race', 'window', 'store', 'summer', 'train', 'sleep', 'prove', 'lone', 'leg', 'exercise', 'wall', 'catch', 'mount', 'wish', 'sky', 'board', 'joy', 'winter', 'sat', 'written', 'wild', 'instrument', 'kept', 'glass', 'grass', 'cow', 'job', 'edge', 'sign', 'visit', 'past', 'soft', 'fun', 'bright', 'gas', 'weather', 'month', 'million', 'bear', 'finish', 'happy', 'hope', 'flower', 'clothe', 'strange', 'gone', 'jump', 'baby', 'eight', 'village', 'meet', 'root', 'buy', 'raise', 'solve', 'metal', 'whether', 'push', 'seven', 'paragraph', 'third', 'shall', 'held', 'hair', 'describe', 'cook', 'floor', 'either', 'result', 'burn', 'hill', 'safe', 'cat', 'century', 'consider', 'type', 'law', 'bit', 'coast', 'copy', 'phrase', 'silent', 'tall', 'sand', 'soil', 'roll', 'temperature', 'finger', 'industry', 'value', 'fight', 'lie', 'beat', 'excite', 'natural', 'view', 'sense', 'ear', 'else', 'quite', 'broke', 'case', 'middle', 'kill', 'son', 'lake', 'moment', 'scale', 'loud', 'spring', 'observe', 'child', 'straight', 'consonant', 'nation', 'dictionary', 'milk', 'speed', 'method', 'organ', 'pay', 'age', 'section', 'dress', 'cloud', 'surprise', 'quiet', 'stone', 'tiny', 'climb', 'cool', 'design', 'poor', 'lot', 'experiment', 'bottom', 'key', 'iron', 'single', 'stick', 'flat', 'twenty', 'skin', 'smile', 'crease', 'hole', 'trade', 'melody', 'trip', 'office', 'receive', 'row', 'mouth', 'exact', 'symbol', 'die', 'least', 'trouble', 'shout', 'except', 'wrote', 'seed', 'tone', 'join', 'suggest', 'clean', 'break', 'lady', 'yard', 'rise', 'bad', 'blow', 'oil', 'blood', 'touch', 'grew', 'cent', 'mix', 'team', 'wire', 'cost', 'lost', 'brown', 'wear', 'garden', 'equal', 'sent', 'choose', 'fell', 'fit', 'flow', 'fair', 'bank', 'collect', 'save', 'control', 'decimal', 'gentle', 'woman', 'captain', 'practice', 'separate', 'difficult', 'doctor', 'please', 'protect', 'noon', 'whose', 'locate', 'ring', 'character', 'insect', 'caught', 'period', 'indicate', 'radio', 'spoke', 'atom', 'human', 'history', 'effect', 'electric', 'expect', 'crop', 'modern', 'element', 'hit', 'student', 'corner', 'party', 'supply', 'bone', 'rail', 'imagine', 'provide', 'agree', 'thus', 'capital', \"won't\", 'chair', 'danger', 'fruit', 'rich', 'thick', 'soldier', 'process', 'operate', 'guess', 'necessary', 'sharp', 'wing', 'create', 'neighbor', 'wash', 'bat', 'rather', 'crowd', 'corn', 'compare', 'poem', 'string', 'bell', 'depend', 'meat', 'rub', 'tube', 'famous', 'dollar', 'stream', 'fear', 'sight', 'thin', 'triangle', 'planet', 'hurry', 'chief', 'colony', 'clock', 'mine', 'tie', 'enter', 'major', 'fresh', 'search', 'send', 'yellow', 'gun', 'allow', 'print', 'dead', 'spot', 'desert', 'suit', 'current', 'lift', 'rose', 'continue', 'block', 'chart', 'hat', 'sell', 'success', 'company', 'subtract', 'event', 'particular', 'deal', 'swim', 'term', 'opposite', 'wife', 'shoe', 'shoulder', 'spread', 'arrange', 'camp', 'invent', 'cotton', 'born', 'determine', 'quart', 'nine', 'truck', 'noise', 'level', 'chance', 'gather', 'shop', 'stretch', 'throw', 'shine', 'property', 'column', 'molecule', 'select', 'wrong', 'gray', 'repeat', 'require', 'broad', 'prepare', 'salt', 'nose', 'plural', 'anger', 'claim', 'continent', 'oxygen', 'sugar', 'death', 'pretty', 'skill', 'women', 'season', 'solution', 'magnet', 'silver', 'thank', 'branch', 'match', 'suffix', 'especially', 'fig', 'afraid', 'huge', 'sister', 'steel', 'discuss', 'forward', 'similar', 'guide', 'experience', 'score', 'apple', 'bought', 'led', 'pitch', 'coat', 'mass', 'card', 'band', 'rope', 'slip', 'win', 'dream', 'evening', 'condition', 'feed', 'tool', 'total', 'basic', 'smell', 'valley', 'nor', 'double', 'seat', 'arrive', 'master', 'track', 'parent', 'shore', 'division', 'sheet', 'substance', 'favor', 'connect', 'post', 'spend', 'chord', 'fat', 'glad', 'original', 'share', 'station', 'dad', 'bread', 'charge', 'proper', 'bar', 'offer', 'segment', 'slave', 'duck', 'instant', 'market', 'degree', 'populate', 'chick', 'dear', 'enemy', 'reply', 'drink', 'occur', 'support', 'speech', 'nature', 'range', 'steam', 'motion', 'path', 'liquid', 'log', 'meant', 'quotient', 'teeth', 'shell', 'nec', '\\n\\n', '\\n', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~']\n"
     ]
    }
   ],
   "source": [
    "# Got the txt file from here: https://gist.github.com/deekayen/4148741\n",
    "\n",
    "# Common words List to hold common words\n",
    "with open(\"ml-data-input/most-common-words.txt\", \"r\") as common_words_file:\n",
    "    common_tokens = [word[:-1] for word in list(common_words_file)]\n",
    "    common_tokens.append(\"\\n\\n\")\n",
    "    common_tokens.append(\"\\n\")\n",
    "    common_tokens.append(\" \")\n",
    "\n",
    "# Add punctuation to the list of commonalities\n",
    "for char in list(string.punctuation):\n",
    "    common_tokens.append(char)\n",
    "\n",
    "print(common_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to get rid of the 1000 most common used words\n",
    "def common_word_drop(token_list, whitespace_list, label_list, rows):\n",
    "    for word in common_tokens:\n",
    "        if word in token_list:\n",
    "            indices = [i for i, x in enumerate(token_list) if x.lower() == word]\n",
    "            token_list = [token_list[i] for i in range(len(token_list)) if i not in indices]\n",
    "            whitespace_list = [whitespace_list[i] for i in range(len(whitespace_list)) if i not in indices]\n",
    "            label_list = [label_list[i] for i in range(len(label_list)) if i not in indices]\n",
    "            rows = [rows[i] for i in range(len(rows)) if i not in indices]\n",
    "\n",
    "    return token_list, whitespace_list, label_list, rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rows(full_tokens):\n",
    "    rows = []\n",
    "    row_num = 1\n",
    "    for token in full_tokens:\n",
    "        rows.append(row_num)\n",
    "        if token == \"\\n\\n\" or token == \"\\n\":\n",
    "            row_num = row_num + 1\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pii_data_exists(labels):\n",
    "    # Loop over and see if a PII data is found, if it is, return True, else False.\n",
    "    for label in labels:\n",
    "        if label != 'O':\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_label(labels):\n",
    "\n",
    "    # Initialize the indexer and for all labels, find the indexes that have PII data\n",
    "    label_indexes = []\n",
    "    for i in range(len(labels)):\n",
    "        if labels[i] != 'O':\n",
    "            label_indexes.append(i)\n",
    "    \n",
    "    # If there is no PII data, if only one PII data, else multiple data\n",
    "    if len(label_indexes) == 0:\n",
    "        return [-1 for label in labels]\n",
    "    elif len(label_indexes) == 1:\n",
    "        label_range = [-1 for label in labels]\n",
    "        label_range[label_indexes[0]] = 0\n",
    "        return label_range\n",
    "    else:\n",
    "        label_range = [-1 for label in labels]\n",
    "\n",
    "        # Get distance for first PII\n",
    "        first_index = label_indexes[0]\n",
    "        first_pii_distance = label_indexes[1] - label_indexes[0]\n",
    "        label_range[first_index] = first_pii_distance\n",
    "\n",
    "        # Get distance for last PII\n",
    "        last_index = label_indexes[-1]\n",
    "        last_pii_distance = label_indexes[-1] - label_indexes[-2]\n",
    "        label_range[last_index] = last_pii_distance\n",
    "        \n",
    "        # Loop over the second to second last PII and get the distances.\n",
    "        for idx in range(1, len(label_indexes)-1):\n",
    "\n",
    "            # For the middle PII data points. Set the previous and next PII\n",
    "            current_pii = label_indexes[idx]\n",
    "            previous_pii = label_indexes[idx-1]\n",
    "            next_pii = label_indexes[idx+1]\n",
    "\n",
    "            # distances\n",
    "            prev_dist = current_pii - previous_pii\n",
    "            next_dist = next_pii - current_pii\n",
    "\n",
    "            # Append the shortest distance to the current pii data\n",
    "            label_range[current_pii] = min(prev_dist, next_dist)\n",
    "        \n",
    "        # Return the label range.\n",
    "        return label_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_data_for_model(data):\n",
    "\n",
    "    # Get the first value from the data\n",
    "    first_doc = data[0]\n",
    "\n",
    "    # Get rid of common words\n",
    "    all_rows = get_rows(first_doc['tokens'])\n",
    "    tokens, white_spaces, labels, rows = common_word_drop(first_doc['tokens'], first_doc['trailing_whitespace'], first_doc['labels'], all_rows)\n",
    "    closest_labels = get_closest_label(labels)\n",
    "\n",
    "    # Create the initial dataframe from the above data\n",
    "    first_doc_data = {\n",
    "        \"tokens\": tokens,\n",
    "        \"trailing_whitespaces\": white_spaces,\n",
    "        \"capitalized first char\": [True if label[0].isupper() else False for label in tokens],\n",
    "        \"token length\": [len(token) for token in tokens],\n",
    "        \"is_numeric\": [True if token.isnumeric() else False for token in tokens],\n",
    "        \"PII label\": [pii_number_encoding[label] for label in labels],\n",
    "        \"Row\": rows,\n",
    "        \"Closest PII data\": closest_labels\n",
    "    }\n",
    "    raw_df = pd.DataFrame(first_doc_data)\n",
    "\n",
    "    # Loop till the end of the data\n",
    "    for document in data[1: len(data) - 1]:\n",
    "\n",
    "        # Check to see if there exists PII data\n",
    "        if not pii_data_exists(document['labels']):\n",
    "            continue\n",
    "            \n",
    "        # Get rid of common words\n",
    "        all_rows = get_rows(document['tokens'])\n",
    "        tokens, white_spaces, labels, rows = common_word_drop(document['tokens'], document['trailing_whitespace'], document['labels'], all_rows)\n",
    "        closest_labels = get_closest_label(labels)\n",
    "\n",
    "        # Collect the data in the same way\n",
    "        doc_data = {\n",
    "            \"tokens\": tokens,\n",
    "            \"trailing_whitespaces\": white_spaces,\n",
    "            \"capitalized first char\": [True if label[0].isupper() else False for label in tokens],\n",
    "            \"token length\": [len(token) for token in tokens],\n",
    "            \"is_numeric\": [True if token.isnumeric() else False for token in tokens],\n",
    "            \"PII label\": [pii_number_encoding[label] for label in labels],\n",
    "            \"Row\": rows,\n",
    "            \"Closest PII data\": closest_labels\n",
    "        }\n",
    "        df = pd.DataFrame(doc_data)\n",
    "\n",
    "        # Concatenate all the data into one single dataframe\n",
    "        raw_df = pd.concat([raw_df, df], ignore_index=True, sort=False)\n",
    "\n",
    "    # Return the concatenated dataframe\n",
    "    return raw_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>trailing_whitespaces</th>\n",
       "      <th>capitalized first char</th>\n",
       "      <th>token length</th>\n",
       "      <th>is_numeric</th>\n",
       "      <th>PII label</th>\n",
       "      <th>Row</th>\n",
       "      <th>Closest PII data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thinking</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>innovation</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>reflexion</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Avril</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276038</th>\n",
       "      <td>However</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>32</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276039</th>\n",
       "      <td>hindrance</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>32</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276040</th>\n",
       "      <td>stimulate</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>32</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276041</th>\n",
       "      <td>innovative</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>32</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276042</th>\n",
       "      <td>thinking</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>33</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>276043 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            tokens  trailing_whitespaces  capitalized first char  \\\n",
       "0         Thinking                  True                    True   \n",
       "1       innovation                  True                   False   \n",
       "2        reflexion                 False                   False   \n",
       "3            Avril                  True                    True   \n",
       "4             2021                 False                   False   \n",
       "...            ...                   ...                     ...   \n",
       "276038     However                 False                    True   \n",
       "276039   hindrance                  True                   False   \n",
       "276040   stimulate                  True                   False   \n",
       "276041  innovative                 False                   False   \n",
       "276042    thinking                  True                   False   \n",
       "\n",
       "        token length  is_numeric PII label  Row  Closest PII data  \n",
       "0                  8       False         O    1                -1  \n",
       "1                 10       False         O    1                -1  \n",
       "2                  9       False         O    1                -1  \n",
       "3                  5       False         O    1                -1  \n",
       "4                  4        True         O    1                -1  \n",
       "...              ...         ...       ...  ...               ...  \n",
       "276038             7       False         O   32                -1  \n",
       "276039             9       False         O   32                -1  \n",
       "276040             9       False         O   32                -1  \n",
       "276041            10       False         O   32                -1  \n",
       "276042             8       False         O   33                -1  \n",
       "\n",
       "[276043 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the training data and get rid of some unneeded number values\n",
    "# data = engineer_data_for_model(raw_data[0:6000])\n",
    "data = engineer_data_for_model(raw_data)\n",
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
